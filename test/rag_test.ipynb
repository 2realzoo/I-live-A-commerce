{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightRAG CSV파일 인식 테스트\n",
    "### 아직 llama 모델 완성 전이기에 gpt로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lightrag.llm import ollama_model_complete, ollama_embedding\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from lightrag import LightRAG, QueryParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './rag_db_test'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "\n",
    "file_path = 'recommend_test.csv'\n",
    "text_content = textract.process(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ./rag_db_test\n",
      "INFO:lightrag:Load KV llm_response_cache with 3 data\n",
      "INFO:lightrag:Load KV full_docs with 1 data\n",
      "INFO:lightrag:Load KV text_chunks with 4 data\n",
      "INFO:lightrag:Loaded graph from ./rag_db_test\\graph_chunk_entity_relation.graphml with 85 nodes, 48 edges\n",
      "INFO:nano-vectordb:Load (85, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './rag_db_test\\\\vdb_entities.json'} 85 data\n",
      "INFO:nano-vectordb:Load (48, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './rag_db_test\\\\vdb_relationships.json'} 48 data\n",
      "INFO:nano-vectordb:Load (4, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './rag_db_test\\\\vdb_chunks.json'} 4 data\n"
     ]
    }
   ],
   "source": [
    "rag = LightRAG(\n",
    "    working_dir=path,\n",
    "    llm_model_func=gpt_4o_mini_complete\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lightrag:All docs are already in the storage\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "rag.insert(text_content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Truncate 4 to 4 chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, here are the products sorted by the highest similarity score:\n",
      "\n",
      "### Product List with Highest Similarity Scores\n",
      "\n",
      "1. **Product Title:** 피디알엔 재생 크림  \n",
      "   **Link:** [View Product](https://smartstore.naver.com/main/products/3238401934)  \n",
      "   **Price:** 16,000 KRW  \n",
      "\n",
      "2. **Product Title:** 설화수 탄력 크림 75ml  \n",
      "   **Link:** [View Product](https://search.shopping.naver.com/catalog/4157790737)  \n",
      "   **Price:** 36,980 KRW  \n",
      "\n",
      "3. **Product Title:** 대용량 히알루론산 수분 크림 병풀 시카 영양 보습 달팽이 크림 주름개선 px 화장품  \n",
      "   **Link:** [View Product](https://smartstore.naver.com/main/products/4215558437)  \n",
      "   **Price:** 17,800 KRW  \n",
      "\n",
      "### Summary\n",
      "The product with the highest similarity score is the “피디알엔 재생 크림” with a score of 0.5. The next is “설화수 탄력 크림,” followed by the “히알루론산 수분 크림.” Each product varies in price and is available from different online retailers, emphasizing diverse skincare options for consumers.\n"
     ]
    }
   ],
   "source": [
    "print(rag.query(\"Give me 3 list of title, link, lprice of the product with the highest similarity score.\", param=QueryParam(mode='naive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:kw_prompt result:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"high_level_keywords\": [\"Product listings\", \"E-commerce\", \"Pricing\"],\n",
      "  \"low_level_keywords\": [\"Titles\", \"Links\", \"Lowest price\", \"Product details\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Local query uses 1 entites, 2 relations, 2 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Products with the Lowest Price\n",
      "\n",
      "Here are the three products with the lowest listed prices from the provided data:\n",
      "\n",
      "1. **센텔리안24 더 마데카 크림 50ml**\n",
      "   - **Link**: [센텔리안24 더 마데카 크림](https://search.shopping.naver.com/catalog/29818094622)\n",
      "   - **Price**: 6,400 KRW\n",
      "\n",
      "2. **닥터지 블랙 스네일 크림 50ml**\n",
      "   - **Link**: [닥터지 블랙 스네일 크림](https://search.shopping.naver.com/catalog/14184334980)\n",
      "   - **Price**: 8,140 KRW\n",
      "\n",
      "3. **센텔리안24 마데카 크림 액티브 스킨 포뮬러 50ml**\n",
      "   - **Link**: [센텔리안24 마데카 크림 액티브 스킨 포뮬러](https://search.shopping.naver.com/catalog/21900258098)\n",
      "   - **Price**: 6,290 KRW\n",
      "\n",
      "These selections reflect the lowest prices available for skincare products listed in your data. Please let me know if you need any further information!\n"
     ]
    }
   ],
   "source": [
    "print(rag.query(\"Give me 3 list of title, link, lprice of the product with the lowest lprice.\", param=QueryParam(mode='local')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통합 LightRAG와 LangChain 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 통합 LightRAG 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lightrag.llm import ollama_model_complete, ollama_embedding\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from lightrag import LightRAG, QueryParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../rag_db_test'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ../rag_db_test\n",
      "INFO:lightrag:Load KV llm_response_cache with 1 data\n",
      "INFO:lightrag:Load KV full_docs with 2 data\n",
      "INFO:lightrag:Load KV text_chunks with 14 data\n",
      "INFO:lightrag:Loaded graph from ../rag_db_test\\graph_chunk_entity_relation.graphml with 174 nodes, 108 edges\n",
      "INFO:nano-vectordb:Load (173, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../rag_db_test\\\\vdb_entities.json'} 173 data\n",
      "INFO:nano-vectordb:Load (108, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../rag_db_test\\\\vdb_relationships.json'} 108 data\n",
      "INFO:nano-vectordb:Load (14, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../rag_db_test\\\\vdb_chunks.json'} 14 data\n"
     ]
    }
   ],
   "source": [
    "rag = LightRAG(\n",
    "    working_dir=path,\n",
    "    llm_model_func=gpt_4o_mini_complete\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "Chunking documents: 100%|██████████| 1/1 [00:00<00:00,  4.94doc/s]\n",
      "INFO:lightrag:[New Chunks] inserting 9 chunks\n",
      "INFO:lightrag:Inserting 9 vectors to chunks\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.71s/batch]\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/9 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 22 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 1/9 [00:17<02:16, 17.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 35 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 3/9 [00:17<00:27,  4.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 46 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 4/9 [00:18<00:17,  3.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 58 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 5/9 [00:21<00:12,  3.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 72 entities(duplicated), 60 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 6/9 [00:22<00:07,  2.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 94 entities(duplicated), 66 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 7/9 [00:26<00:05,  2.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 117 entities(duplicated), 79 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 8/9 [00:26<00:01,  2.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 146 entities(duplicated), 88 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 9/9 [00:30<00:00,  3.39s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 102/102 [00:00<00:00, 10503.52entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 77/77 [00:00<00:00, 25884.54relationship/s]\n",
      "INFO:lightrag:Inserting 102 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/4 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:03<00:00,  1.11batch/s]\n",
      "INFO:lightrag:Inserting 77 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/3 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:03<00:00,  1.10s/batch]\n",
      "INFO:lightrag:Writing graph with 103 nodes, 77 edges\n"
     ]
    }
   ],
   "source": [
    "# 추천시스템 파일\n",
    "import textract\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "file_path = 'recommend_test.csv'\n",
    "text_content = textract.process(file_path)\n",
    "\n",
    "rag.insert(text_content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "Chunking documents: 100%|██████████| 1/1 [00:00<00:00, 123.01doc/s]\n",
      "INFO:lightrag:[New Chunks] inserting 5 chunks\n",
      "INFO:lightrag:Inserting 5 vectors to chunks\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/batch]\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/5 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 16 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  20%|██        | 1/5 [00:26<01:45, 26.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 33 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  40%|████      | 2/5 [00:26<00:33, 11.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 58 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  60%|██████    | 3/5 [00:29<00:14,  7.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 71 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  80%|████████  | 4/5 [00:29<00:04,  4.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 89 entities(duplicated), 32 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 5/5 [00:36<00:00,  7.35s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 73/73 [00:00<?, ?entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 31/31 [00:00<00:00, 3438.68relationship/s]\n",
      "INFO:lightrag:Inserting 73 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/3 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:01<00:00,  1.55batch/s]\n",
      "INFO:lightrag:Inserting 31 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.81s/batch]\n",
      "INFO:lightrag:Writing graph with 174 nodes, 108 edges\n"
     ]
    }
   ],
   "source": [
    "# STT 파일\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "with open('./stt_file_test.txt') as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 통합 RAG 개별 성능 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Truncate 10 to 3 chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, the product with the highest similarity score is **\"식품 샘플 복숭아 복숭아\"**. Below are three entries of this product, detailing their titles, links, and prices:\n",
      "\n",
      "### Products with Highest Similarity Score\n",
      "\n",
      "1. **Product Title:** HIRAISM 8cm 8 식품 샘플 복숭아 복숭아 과일 과일 가짜 진짜 똑같이  \n",
      "   **Link:** [View Product](https://link.coupang.com/re/PCSNAVERPCSDP?pageKey=8272581325&ctag=8272581325&lptag=V91629104972&itemId=23843018242&vendorItemId=91629104972&spec=10305199)  \n",
      "   **Price:** 61,880 KRW  \n",
      "\n",
      "2. **Product Title:** HIRAISM 8cm 8 식품 샘플 복숭아 복숭아 과일 과일 가짜 진짜 똑같이  \n",
      "   **Link:** [View Product](https://link.coupang.com/re/PCSNAVERPCSDP?pageKey=8272581325&ctag=8272581325&lptag=V91441449405&itemId=23843018242&vendorItemId=91441449405&spec=10305199)  \n",
      "   **Price:** 50,900 KRW  \n",
      "\n",
      "3. **Product Title:** HIRAISM 8cm 8 식품 샘플 복숭아 복숭아 과일 과일 가짜 진짜 똑같이  \n",
      "   **Link:** [View Product](https://link.coupang.com/re/PCSNAVERPCSDP?pageKey=8272581325&ctag=8272581325&lptag=V90866498117&itemId=23843018242&vendorItemId=90866498117&spec=10305199)  \n",
      "   **Price:** 56,640 KRW  \n",
      "\n",
      "These entries represent different listings for the same product, showcasing variations in price across platforms.\n"
     ]
    }
   ],
   "source": [
    "# 추천시스템\n",
    "print(rag.query(\"Give me 3 list of title, link, lprice of the product with the highest similarity score.\", param=QueryParam(mode='naive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Truncate 5 to 3 chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 방송 내용 요약\n",
      "\n",
      "이번 방송에서는 여러 가지 맛있고 흥미로운 상품들을 소개하는 시간이었습니다. 특히, 사각형 피자와 풍미 가득한 레드골드 과일에 대한 설명이 주를 이뤘습니다. 방송자는 이러한 제품들이 다른 곳과는 비교할 수 없는 품질을 자랑한다고 강조하며, 제품의 시각적 매력과 함께 고객 피드백을 언급했습니다.\n",
      "\n",
      "#### 제품 소개\n",
      "- **김천 레드골드**: 크고 아름다우며 애플망고와 비슷한 맛을 맡을 수 있는 품질 높은 과일입니다. 맛이 너무 달콤하고 향이 좋다고 합니다.\n",
      "- **피자**: 여러 가지 재료가 아낌없이 들어가고, 비주얼과 식감 모두 우수하다는 점이 강조되었습니다. 특히, 슈퍼 기름지지 않고 깔끔한 맛이 특징입니다.\n",
      "\n",
      "#### 이벤트 및 홍보\n",
      "방송 도중 구매 인증을 하면 포인트를 얻을 수 있는 룰렛 이벤트가 진행되고 있었습니다. 고객들에게 적극적인 참여를 유도하며, 구매 후 구매번호를 입력해줄 것을 요청했습니다. 이러한 이벤트는 고객들로부터 긍정적인 반응을 얻고 있는 것으로 보입니다.\n",
      "\n",
      "#### 고객 반응\n",
      "방송 중 여러 고객들이 실시간으로 참여하고 있으며, 지속적인 구매가 이어지는 모습을 보였습니다. 방송자는 고객들에게 감사를 표하며, 고객들의 피드백이 곧바로 품질 개선이나 상품 구입에 영향을 미친다고 강조했습니다.\n",
      "\n",
      "전반적으로 방송에서는 고품질 제품을 적극 홍보하며, 고객과의 소통을 통해 상품에 대한 신뢰를 쌓고자 하는 모습을 보여주었습니다. 고객들이 제품에 대해 궁금하게 생각할 수 있는 다양한 정보를 제공하고, 쇼핑의 재미를 더하는 이벤트를 통해 참여를 유도하는 방식으로 진행된 것이 특징적입니다.\n"
     ]
    }
   ],
   "source": [
    "# STT\n",
    "print(rag.query(\"방송 내용을 요약해봐\", param=QueryParam(mode='naive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Truncate 14 to 3 chunks\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To assist viewers who are interested in purchasing products similar to those showcased on the broadcast, I have compiled a list of five items with the highest similarity scores. The list includes the product titles, purchase links, and their prices. \n",
      "\n",
      "### Similar Products List\n",
      "\n",
      "1. **[제철과일] 인생 복숭아 청도 갤럭시농장 복숭아 [복숭아 4kg]**\n",
      "   - **Link:** [View Product](http://mallscm.epost.go.kr/postif/epostPartner.do?p=naver&Gbn=51&goodsCd=EA1048314&pavlnDivCd=02&goodsDispTypeCd=&goodsDispTypeDtlCd=&ctgryCd=101202305)\n",
      "   - **Price:** 20,900 KRW\n",
      "   - **Similarity Score:** 0.8\n",
      "\n",
      "2. **제철 과일 황도 복숭아 4kg 고당도 복숭아 선물 세트 말랑이 복숭아**\n",
      "   - **Link:** [View Product](https://smartstore.naver.com/main/products/10764777449)\n",
      "   - **Price:** 59,400 KRW\n",
      "   - **Similarity Score:** 0.718\n",
      "\n",
      "3. **석가과일 복숭아**\n",
      "   - **Link:** [View Product](https://link.coupang.com/re/PCSNAVERPCSDP?pageKey=8454673433&ctag=8454673433&lptag=I23477726216&itemId=23477726216&vendorItemId=90504233896&spec=10305199)\n",
      "   - **Price:** 24,730 KRW\n",
      "   - **Similarity Score:** 0.667\n",
      "\n",
      "4. **과일모형 복숭아**\n",
      "   - **Link:** [View Product](https://link.gmarket.co.kr/gate/pcs?item-no=1800713597&sub-id=1003&service-code=10000003&lcd=100000093)\n",
      "   - **Price:** 1,800 KRW\n",
      "   - **Similarity Score:** 0.667\n",
      "\n",
      "5. **설아복숭아 겨울 복숭아 황귀비 양홍장 복숭아 햇사레 백도 물복 2kg**\n",
      "   - **Link:** [View Product](https://smartstore.naver.com/main/products/8901259750)\n",
      "   - **Price:** 79,900 KRW\n",
      "   - **Similarity Score:** 0.655\n",
      "\n",
      "### Conclusion\n",
      "These products were selected based on their high similarity scores, indicating they are closely related to the items discussed during the broadcast. You can explore the provided links to find out more details or make a purchase. Happy shopping!\n"
     ]
    }
   ],
   "source": [
    "# STT + 추천시스템\n",
    "print(rag.query(\"방송 내용에서 보여주는 상품과 비슷한 상품을 사고싶어하는 시청자들을 위해 the highest similarity score를 기준으로 title, link, lprice로 구성된 목록 5가지를 가져와와\", param=QueryParam(mode='naive')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain, RetrievalQA, RetrievalQAWithSourcesChain, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent,tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6888\\2057052378.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm_model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)\n"
     ]
    }
   ],
   "source": [
    "llm_model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = '주어진 답변에 대해 대답해'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리트리버를 프롬프트에서 연결이 아닌 개별적으로 연결 \n",
    "llm_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', f'{test_prompt}'),\n",
    "        ('human', '{input}'),\n",
    "        ('placeholder', '{agent_scratchpad}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def insert_rag(input):\n",
    "    \"\"\"\n",
    "    관련 내용을 RAG 시스템에 질의하여 결과를 반환하는 툴입니다.\n",
    "    \"\"\"\n",
    "    path = 'rag_db_test'\n",
    "    rag = LightRAG(\n",
    "        working_dir=path,\n",
    "        llm_model_func=gpt_4o_mini_complete\n",
    "    )\n",
    "    resp = rag.query(input, param=QueryParam(mode='naive'))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [insert_rag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tool_calling_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\I-live-A-commerce\\.venv\\Lib\\site-packages\\langchain\\agents\\tool_calling_agent\\base.py:98\u001b[0m, in \u001b[0;36mcreate_tool_calling_agent\u001b[1;34m(llm, tools, prompt, message_formatter)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(llm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbind_tools\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function requires a .bind_tools method be implemented on the LLM.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    101\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m    102\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: message_formatter(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;241m|\u001b[39m ToolsAgentOutputParser()\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\I-live-A-commerce\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1115\u001b[0m, in \u001b[0;36mBaseChatModel.bind_tools\u001b[1;34m(self, tools, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_tools\u001b[39m(\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1110\u001b[0m     tools: Sequence[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[LanguageModelInput, BaseMessage]:\n\u001b[1;32m-> 1115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = create_tool_calling_agent(llm_model, tools, llm_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:kw_prompt result:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"high_level_keywords\": [\"방송 내용 분석\", \"상품\", \"이벤트\"],\n",
      "  \"low_level_keywords\": [\"방송 프로그램\", \"상품 홍보\", \"이벤트 진행\", \"시청자 반응\", \"마케팅 전략\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Local query uses 60 entites, 60 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Global query uses 71 entites, 60 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:kw_prompt result:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"high_level_keywords\": [\"추천 시스템\", \"상품 추천\", \"사용자 경험\"],\n",
      "  \"low_level_keywords\": [\"알고리즘\", \"협업 필터링\", \"콘텐츠 기반 필터링\", \"유사도 측정\", \"고객 선호\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Local query uses 29 entites, 48 relations, 4 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Global query uses 69 entites, 60 relations, 3 text units\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#리트리버를 프롬프트에 연결\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "stt_data = rag.query('방송 내용들 특히 상품과 이벤트 내용을 분석해', param=QueryParam(mode='hybrid'))\n",
    "recommend_data = rag.query('상품의 추천시스템 목록들을 파악해', param=QueryParam(mode='hybrid'))\n",
    "test_prompt = [\n",
    "    '주어진 답변에 대해 대답해',\n",
    "    f'{stt_data}',\n",
    "    f'{recommend_data}'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6888\\4121869898.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "llm_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(test_prompt),\n",
    "        HumanMessagePromptTemplate.from_template('{input}'),\n",
    "        HumanMessagePromptTemplate.from_template('{history}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6888\\2541255541.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm_model,\n",
    "    prompt=llm_prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['물론입니다! 아래는 복숭아와 관련된 비슷한 상품 추천 목록입니다.',\n",
       " '',\n",
       " '### 복숭아 관련 상품 추천 목록',\n",
       " '',\n",
       " '1. **천도 복숭아 세트 (3kg)**',\n",
       " '   - 가격: 25,000 원',\n",
       " '   - 링크: [예시 링크](http://www.example.com/product1)',\n",
       " '   - 설명: 신선한 천도 복숭아로, 과즙이 풍부하고 달콤한 맛이 특징입니다.',\n",
       " '',\n",
       " '2. **유기농 복숭아 (2kg)**',\n",
       " '   - 가격: 30,000 원',\n",
       " '   - 링크: [예시 링크](http://www.example.com/product2)',\n",
       " '   - 설명: 화학 비료와 농약을 사용하지 않은 유기농 복숭아로, 건강을 생각하는 소비자에게 추천합니다.',\n",
       " '',\n",
       " '3. **복숭아 잼 (250g)**',\n",
       " '   - 가격: 8,500 원',\n",
       " '   - 링크: [예시 링크](http://www.example.com/product3)',\n",
       " '   - 설명: 신선한 복숭아로 만든 수제 잼으로, 토스트나 요거트와 함께 즐기기 좋습니다.',\n",
       " '',\n",
       " '4. **복숭아 주스 (1L)**',\n",
       " '   - 가격: 5,000 원',\n",
       " '   - 링크: [예시 링크](http://www.example.com/product4)',\n",
       " '   - 설명: 100% 복숭아로 만든 자연 주스, 인공 첨가물이 없으며 상큼한 맛이 특징입니다.',\n",
       " '',\n",
       " '5. **복숭아 아이스크림 (500ml)**',\n",
       " '   - 가격: 6,000 원',\n",
       " '   - 링크: [예시 링크](http://www.example.com/product5)',\n",
       " '   - 설명: 신선한 복숭아를 사용한 아이스크림으로, 여름철 더위를 식히기에 안성맞춤입니다.',\n",
       " '',\n",
       " '이와 같은 다양한 복숭아 관련 상품들이 소비자에게 선택의 폭을 넓히고, 원하는 제품을 쉽게 찾을 수 있도록 도와줍니다. 각 제품의 링크를 통해 간편하게 구매할 수 있습니다.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke('비슷한 상품 추천해봐')['response']\n",
    "response.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['방송 중 다양한 이벤트가 진행되었습니다. 주요 이벤트는 다음과 같습니다:',\n",
       " '',\n",
       " '1. **프로모션 및 할인 이벤트**: 방송 내내 특별 할인 이벤트가 진행되어 소비자들에게 즉각적인 구매 장려를 제공했습니다. 예를 들어, \"특가 유지\"와 같은 이벤트는 시청자들이 특별한 가격에 상품을 구매할 수 있는 기회를 제공했습니다.',\n",
       " '',\n",
       " '2. **룰렛 및 경품 이벤트**: 룰렛 이벤트를 통해 소비자에게 포인트나 상품을 제공하며, 방송의 재미 요소를 추가했습니다. 고객들은 참여를 통해 보상을 얻고, 이 과정에서 더 활발하게 소통할 수 있었습니다.',\n",
       " '',\n",
       " '3. **시즌별 행사**: \"2023 첫 수확\"과 같은 특별 세션이 마련되어 시즌 상품의 즉시성을 강조했습니다. 이를 통해 소비자들은 특정 시즌의 신선한 과일을 구매할 수 있는 기회를 가졌습니다.',\n",
       " '',\n",
       " '이러한 이벤트들은 소비자들의 관심을 끌고, 구매를 촉진하는 데 효과적이었습니다.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke('이벤트 있었어? 있었다면 어떤 이벤트야?')['response']\n",
    "response.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['이벤트 당첨자에 대한 정보는 방송 후 공지되거나 별도로 발표될 가능성이 높습니다. 룰렛 및 경품 이벤트와 같은 경우, 당첨자는 방송 중 실시간으로 발표되기도 하며, 이후 공식 웹사이트나 소셜 미디어를 통해 확인할 수 있습니다. 따라서 해당 방송의 공식 채널을 확인해 보시는 것이 좋습니다.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke('이벤트 당첨자는 누구야?')['response']\n",
    "response.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
